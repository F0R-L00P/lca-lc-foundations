{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106cf38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e9c4a",
   "metadata": {},
   "source": [
    "## Initialising and invoking a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c3ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"What's the capital of the Moon?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf169b71",
   "metadata": {},
   "source": [
    "## Customising your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f50c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"gpt-5-nano\",\n",
    "    # Kwargs passed to the model:\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "response = model.invoke(\"What's the capital of the Moon?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20521bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Moon is not a country or a sovereign state, so it doesn't have a capital. The Moon is a natural satellite that orbits the Earth. While humans have walked on the Moon during NASA's Apollo missions, there are no permanent human settlements or governments on the Moon.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ibm import ChatWatsonx\n",
    "load_dotenv()\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 100,\n",
    "}\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"meta-llama/llama-4-maverick-17b-128e-instruct-fp8\",\n",
    "    url=os.environ[\"WATSONX_URL\"],\n",
    "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
    "    params=parameters,\n",
    ")\n",
    "\n",
    "response = model.invoke(\"What's the capital of the Moon?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14f450",
   "metadata": {},
   "source": [
    "## Model Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf1d9f",
   "metadata": {},
   "source": [
    "https://docs.langchain.com/oss/python/integrations/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db029be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"claude-sonnet-4-5\")\n",
    "\n",
    "response = model.invoke(\"What's the capital of the Moon?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-3-pro-preview\")\n",
    "\n",
    "response = model.invoke(\"What's the capital of the Moon?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc723f48",
   "metadata": {},
   "source": [
    "## Initialising and invoking an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbc17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(model=\"claude-sonnet-4-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5251725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's the capital of the Moon?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac95763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's the capital of the Moon?\", additional_kwargs={}, response_metadata={}, id='84da1f30-524e-47ea-aabf-f82b65abfb2a'),\n",
      "              AIMessage(content='The Moon is a natural satellite and does not have a capital city. It is not a country or a sovereign state, so it does not have a government or administrative center. Would you like to know more about the Moon or its exploration history?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 85, 'total_tokens': 135}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-958df3cfd4eaa6e64082f5c1b4207134---175a6610-b7c3-4a12-8e26-8490863c73ca', usage_metadata={'input_tokens': 85, 'output_tokens': 50, 'total_tokens': 135})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a8e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Moon is a natural satellite and does not have a capital city. It is not a country or a sovereign state, so it does not have a government or administrative center. Would you like to know more about the Moon or its exploration history?\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5da573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's the capital of the Moon?\", additional_kwargs={}, response_metadata={}, id='164bcab2-89b7-41b0-ab7a-b129ce67ac95'),\n",
      "              AIMessage(content='The capital of the Moon is Luna City.', additional_kwargs={}, response_metadata={}, id='085b3418-a528-473f-b25d-d1ab46af9914'),\n",
      "              HumanMessage(content='Interesting, tell me more about Luna City', additional_kwargs={}, response_metadata={}, id='0665ca37-7a7d-4edb-8dc2-5ed28e79225b'),\n",
      "              AIMessage(content='The Moon is a natural satellite and does not have a capital city. It is not a sovereign state or a country with a government or administrative divisions. Therefore, there is no such place as Luna City or any other capital city on the Moon. The Moon is simply a rocky, airless body that orbits the Earth. Would you like to know more about the Moon or space exploration?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 113, 'total_tokens': 191}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-5d986b2bd2c9f8ba71f3aed456dda76a---6438bc3b-f250-404c-8d6d-a150551da846', usage_metadata={'input_tokens': 113, 'output_tokens': 78, 'total_tokens': 191})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's the capital of the Moon?\"),\n",
    "    AIMessage(content=\"The capital of the Moon is Luna City.\"),\n",
    "    HumanMessage(content=\"Interesting, tell me more about Luna City\")]}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf635e",
   "metadata": {},
   "source": [
    "## Streaming Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7075c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna City is not the capital of the Moon because it is not a real city on the Moon. While there have been several manned missions to the Moon as part of NASA's Apollo program, no human settlements or cities have been established there yet.\n",
      "\n",
      "To get the most up-to-date information on lunar missions and exploration, I can try to find the latest news on this topic. I will use the search tool to look for recent developments. \n",
      "\n",
      "<|python_start|>"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me all about Luna City, the capital of the Moon\")]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "\n",
    "    # token is a message chunk with token content\n",
    "    # metadata contains which node produced the token\n",
    "    \n",
    "    if token.content:  # Check if there's actual content\n",
    "        print(token.content, end=\"\", flush=True)  # Print token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ef691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mType:\u001b[39m        ChatWatsonx\n",
      "\u001b[31mString form:\u001b[39m model_id='meta-llama/llama-4-maverick-17b-128e-instruct-fp8' project_id='80889a7e-01c7-4dcd-898a- <...> tsonx_ai.foundation_models.inference.model_inference.ModelInference object at 0x000001E7163686E0>\n",
      "\u001b[31mFile:\u001b[39m        c:\\users\\behna\\documents\\lca-lc-foundations\\.venv\\lib\\site-packages\\langchain_ibm\\chat_models.py\n",
      "\u001b[31mDocstring:\u001b[39m  \n",
      "`IBM watsonx.ai` chat models integration.\n",
      "\n",
      "???+ info \"Setup\"\n",
      "\n",
      "    To use, you should have `langchain_ibm` python package installed,\n",
      "    and the environment variable `WATSONX_API_KEY` set with your API key, or pass\n",
      "    it as a named parameter `api_key` to the constructor.\n",
      "\n",
      "    ```bash\n",
      "    pip install -U langchain-ibm\n",
      "\n",
      "    # or using uv\n",
      "    uv add langchain-ibm\n",
      "    ```\n",
      "\n",
      "    ```bash\n",
      "    export WATSONX_API_KEY=\"your-api-key\"\n",
      "    ```\n",
      "\n",
      "    !!! deprecated\n",
      "        `apikey` and `WATSONX_APIKEY` are deprecated and will be removed in\n",
      "        version `2.0.0`. Use `api_key` and `WATSONX_API_KEY` instead.\n",
      "\n",
      "??? info \"Instantiate\"\n",
      "\n",
      "    Create a model instance with desired params. For example:\n",
      "\n",
      "    ```python\n",
      "    from langchain_ibm import ChatWatsonx\n",
      "    from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
      "\n",
      "    parameters = TextChatParameters(\n",
      "        top_p=1, temperature=0.5, max_completion_tokens=None\n",
      "    )\n",
      "\n",
      "    model = ChatWatsonx(\n",
      "        model_id=\"meta-llama/llama-3-3-70b-instruct\",\n",
      "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
      "        project_id=\"*****\",\n",
      "        params=parameters,\n",
      "        # api_key=\"*****\"\n",
      "    )\n",
      "    ```\n",
      "\n",
      "??? info \"Invoke\"\n",
      "\n",
      "    Generate a response from the model:\n",
      "\n",
      "    ```python\n",
      "    messages = [\n",
      "        (\n",
      "            \"system\",\n",
      "            \"You are a helpful translator. Translate the user sentence to French.\",\n",
      "        ),\n",
      "        (\"human\", \"I love programming.\"),\n",
      "    ]\n",
      "    model.invoke(messages)\n",
      "    ```\n",
      "\n",
      "    Results in an `AIMessage` response:\n",
      "\n",
      "    ```python\n",
      "    AIMessage(\n",
      "        content=\"J'adore programmer.\",\n",
      "        additional_kwargs={},\n",
      "        response_metadata={\n",
      "            \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 30,\n",
      "                \"total_tokens\": 37,\n",
      "            },\n",
      "            \"model_name\": \"ibm/granite-3-3-8b-instruct\",\n",
      "            \"system_fingerprint\": \"\",\n",
      "            \"finish_reason\": \"stop\",\n",
      "        },\n",
      "        id=\"chatcmpl-529352c4-93ba-4801-8f1d-a3b4e3935194---daed91fb74d0405f200db1e63da9a48a---7a3ef799-4413-47e4-b24c-85d267e37fa2\",\n",
      "        usage_metadata={\"input_tokens\": 30, \"output_tokens\": 7, \"total_tokens\": 37},\n",
      "    )\n",
      "    ```\n",
      "\n",
      "??? info \"Stream\"\n",
      "\n",
      "    Stream a response from the model:\n",
      "\n",
      "    ```python\n",
      "    for chunk in model.stream(messages):\n",
      "        print(chunk.text)\n",
      "    ```\n",
      "\n",
      "    Results in a sequence of `AIMessageChunk` objects with partial content:\n",
      "\n",
      "    ```python\n",
      "    AIMessageChunk(content=\"\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(content=\"J\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(content=\"'\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(content=\"ad\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(content=\"or\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(\n",
      "        content=\" programmer\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\"\n",
      "    )\n",
      "    AIMessageChunk(content=\".\", id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\")\n",
      "    AIMessageChunk(\n",
      "        content=\"\",\n",
      "        response_metadata={\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"model_name\": \"ibm/granite-3-3-8b-instruct\",\n",
      "        },\n",
      "        id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\",\n",
      "    )\n",
      "    AIMessageChunk(\n",
      "        content=\"\",\n",
      "        id=\"run--e48a38d3-1500-4b5e-870c-6313e8cff775\",\n",
      "        usage_metadata={\"input_tokens\": 30, \"output_tokens\": 7, \"total_tokens\": 37},\n",
      "    )\n",
      "    ```\n",
      "\n",
      "    To collect the full message, you can concatenate the chunks:\n",
      "\n",
      "    ```python\n",
      "    stream = model.stream(messages)\n",
      "    full = next(stream)\n",
      "    for chunk in stream:\n",
      "        full += chunk\n",
      "\n",
      "    full\n",
      "    ```\n",
      "\n",
      "    ```python\n",
      "    AIMessageChunk(\n",
      "        content=\"J'adore programmer.\",\n",
      "        response_metadata={\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"model_name\": \"ibm/granite-3-3-8b-instruct\",\n",
      "        },\n",
      "        id=\"chatcmpl-88a48b71-c149-4a0c-9c02-d6b97ca5dc6c---b7ba15879a8c5283b1e8a3b8db0229f0---0037ca4f-8a74-4f84-a46c-ab3fd1294f24\",\n",
      "        usage_metadata={\"input_tokens\": 30, \"output_tokens\": 7, \"total_tokens\": 37},\n",
      "    )\n",
      "    ```\n",
      "\n",
      "??? info \"Async\"\n",
      "\n",
      "    Asynchronous equivalents of `invoke`, `stream`, and `batch` are also available:\n",
      "\n",
      "    ```python\n",
      "    # Invoke\n",
      "    await model.ainvoke(messages)\n",
      "\n",
      "    # Stream\n",
      "    async for chunk in model.astream(messages):\n",
      "        print(chunk.text)\n",
      "\n",
      "    # Batch\n",
      "    await model.abatch([messages])\n",
      "    ```\n",
      "\n",
      "    Results in an `AIMessage` response:\n",
      "\n",
      "    ```python\n",
      "    AIMessage(\n",
      "        content=\"J'adore programmer.\",\n",
      "        additional_kwargs={},\n",
      "        response_metadata={\n",
      "            \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 30,\n",
      "                \"total_tokens\": 37,\n",
      "            },\n",
      "            \"model_name\": \"ibm/granite-3-3-8b-instruct\",\n",
      "            \"system_fingerprint\": \"\",\n",
      "            \"finish_reason\": \"stop\",\n",
      "        },\n",
      "        id=\"chatcmpl-5bef2d81-ef56-463b-a8fa-c2bcc2a3c348---821e7750d18925f2b36226db66667e26---6396c786-9da9-4468-883e-11ed90a05937\",\n",
      "        usage_metadata={\"input_tokens\": 30, \"output_tokens\": 7, \"total_tokens\": 37},\n",
      "    )\n",
      "    ```\n",
      "\n",
      "    For batched calls, results in a `list[AIMessage]`.\n",
      "\n",
      "??? info \"Tool calling\"\n",
      "\n",
      "    ```python\n",
      "    from pydantic import BaseModel, Field\n",
      "\n",
      "\n",
      "    class GetWeather(BaseModel):\n",
      "        '''Get the current weather in a given location'''\n",
      "\n",
      "        location: str = Field(\n",
      "            ..., description=\"The city and state, e.g. San Francisco, CA\"\n",
      "        )\n",
      "\n",
      "\n",
      "    class GetPopulation(BaseModel):\n",
      "        '''Get the current population in a given location'''\n",
      "\n",
      "        location: str = Field(\n",
      "            ..., description=\"The city and state, e.g. San Francisco, CA\"\n",
      "        )\n",
      "\n",
      "\n",
      "    model_with_tools = model.bind_tools(\n",
      "        [GetWeather, GetPopulation]\n",
      "        # strict = True  # Enforce tool args schema is respected\n",
      "    )\n",
      "    ai_msg = model_with_tools.invoke(\n",
      "        \"Which city is hotter today and which is bigger: LA or NY?\"\n",
      "    )\n",
      "    ai_msg.tool_calls\n",
      "    ```\n",
      "\n",
      "    ```python\n",
      "    [\n",
      "        {\n",
      "            \"name\": \"GetWeather\",\n",
      "            \"args\": {\"location\": \"Los Angeles, CA\"},\n",
      "            \"id\": \"chatcmpl-tool-59632abcee8f48a18a5f3a81422b917b\",\n",
      "            \"type\": \"tool_call\",\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"GetWeather\",\n",
      "            \"args\": {\"location\": \"New York, NY\"},\n",
      "            \"id\": \"chatcmpl-tool-c6f3b033b4594918bb53f656525b0979\",\n",
      "            \"type\": \"tool_call\",\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"GetPopulation\",\n",
      "            \"args\": {\"location\": \"Los Angeles, CA\"},\n",
      "            \"id\": \"chatcmpl-tool-175a23281e4747ea81cbe472b8e47012\",\n",
      "            \"type\": \"tool_call\",\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"GetPopulation\",\n",
      "            \"args\": {\"location\": \"New York, NY\"},\n",
      "            \"id\": \"chatcmpl-tool-e1ccc534835945aebab708eb5e685bf7\",\n",
      "            \"type\": \"tool_call\",\n",
      "        },\n",
      "    ]\n",
      "    ```\n",
      "\n",
      "??? info \"Reasoning output\"\n",
      "\n",
      "    ```python\n",
      "    from langchain_ibm import ChatWatsonx\n",
      "    from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
      "\n",
      "    parameters = TextChatParameters(\n",
      "        include_reasoning=True, reasoning_effort=\"medium\"\n",
      "    )\n",
      "\n",
      "    model = ChatWatsonx(\n",
      "        model_id=\"openai/gpt-oss-120b\",\n",
      "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
      "        project_id=\"*****\",\n",
      "        params=parameters,\n",
      "        # api_key=\"*****\"\n",
      "    )\n",
      "\n",
      "    response = model.invoke(\"What is 3^3?\")\n",
      "\n",
      "    # Response text\n",
      "    print(f\"Output: {response.content}\")\n",
      "\n",
      "    # Reasoning summaries\n",
      "    print(f\"Reasoning: {response.additional_kwargs['reasoning_content']}\")\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    Output: 3^3 = 27\n",
      "    Reasoning: The user asks \"What is 3^3?\" That's 27. Provide answer.\n",
      "    ```\n",
      "\n",
      "    !!! version-added \"Added in version 0.3.19: Updated `AIMessage` format\"\n",
      "        [`langchain-ibm >= 0.3.19`](https://pypi.org/project/langchain-ibm/#history)\n",
      "        allows users to set Reasoning output parameters and will format output from\n",
      "        reasoning summaries into `additional_kwargs` field.\n",
      "\n",
      "??? info \"Structured output\"\n",
      "\n",
      "    ```python\n",
      "    from pydantic import BaseModel, Field\n",
      "\n",
      "\n",
      "    class Joke(BaseModel):\n",
      "        '''Joke to tell user.'''\n",
      "\n",
      "        setup: str = Field(description=\"The setup of the joke\")\n",
      "        punchline: str = Field(description=\"The punchline to the joke\")\n",
      "        rating: int | None = Field(description=\"How funny the joke is, 1 to 10\")\n",
      "\n",
      "\n",
      "    structured_model = model.with_structured_output(Joke)\n",
      "    structured_model.invoke(\"Tell me a joke about cats\")\n",
      "    ```\n",
      "\n",
      "    ```python\n",
      "    Joke(\n",
      "        setup=\"Why was the cat sitting on the computer?\",\n",
      "        punchline=\"To keep an eye on the mouse!\",\n",
      "        rating=None,\n",
      "    )\n",
      "    ```\n",
      "\n",
      "    See `with_structured_output` for more info.\n",
      "\n",
      "??? info \"JSON mode\"\n",
      "\n",
      "    ```python\n",
      "    json_model = model.bind(response_format={\"type\": \"json_object\"})\n",
      "    ai_msg = json_model.invoke(\n",
      "        “Return JSON with 'random_ints': an array of 10 random integers from 0-99.”\n",
      "    )\n",
      "    ai_msg.content\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    '{\\n  \"random_ints\": [12, 34, 56, 78, 10, 22, 44, 66, 88, 99]\\n}'\n",
      "    ```\n",
      "\n",
      "??? info \"Image input\"\n",
      "\n",
      "    ```python\n",
      "    import base64\n",
      "    import httpx\n",
      "    from langchain.messages import HumanMessage\n",
      "\n",
      "    image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
      "    image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
      "    message = HumanMessage(\n",
      "        content=[\n",
      "            {\"type\": \"text\", \"text\": \"describe the weather in this image\"},\n",
      "            {\n",
      "                \"type\": \"image_url\",\n",
      "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
      "            },\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    ai_msg = model.invoke([message])\n",
      "    ai_msg.content\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    \"The weather in the image presents a clear, sunny day with good visibility\n",
      "    and no immediate signs of rain or strong winds. The vibrant blue sky with\n",
      "    scattered white clouds gives the impression of a tranquil, pleasant day\n",
      "    conducive to outdoor activities.\"\n",
      "    ```\n",
      "\n",
      "??? info \"Token usage\"\n",
      "\n",
      "    ```python\n",
      "    ai_msg = model.invoke(messages)\n",
      "    ai_msg.usage_metadata\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    {'input_tokens': 30, 'output_tokens': 7, 'total_tokens': 37}\n",
      "    ```\n",
      "\n",
      "    ```python\n",
      "    stream = model.stream(messages)\n",
      "    full = next(stream)\n",
      "    for chunk in stream:\n",
      "        full += chunk\n",
      "    full.usage_metadata\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    {'input_tokens': 30, 'output_tokens': 7, 'total_tokens': 37}\n",
      "    ```\n",
      "\n",
      "??? info \"Logprobs\"\n",
      "\n",
      "    ```python\n",
      "    logprobs_model = model.bind(logprobs=True)\n",
      "    ai_msg = logprobs_model.invoke(messages)\n",
      "    ai_msg.response_metadata[\"logprobs\"]\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    {\n",
      "        'content': [\n",
      "            {\n",
      "                'token': 'J',\n",
      "                'logprob': -0.0017940393\n",
      "            },\n",
      "            {\n",
      "                'token': \"'\",\n",
      "                'logprob': -1.7523613e-05\n",
      "            },\n",
      "            {\n",
      "                'token': 'ad',\n",
      "                'logprob': -0.16112353\n",
      "            },\n",
      "            {\n",
      "                'token': 'ore',\n",
      "                'logprob': -0.0003091811\n",
      "            },\n",
      "            {\n",
      "                'token': ' programmer',\n",
      "                'logprob': -0.24849245\n",
      "            },\n",
      "            {\n",
      "                'token': '.',\n",
      "                'logprob': -2.5033638e-05\n",
      "            },\n",
      "            {\n",
      "                'token': '<|end_of_text|>',\n",
      "                'logprob': -7.080781e-05\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "    ```\n",
      "\n",
      "??? info \"Response metadata\"\n",
      "\n",
      "    ```python\n",
      "    ai_msg = model.invoke(messages)\n",
      "    ai_msg.response_metadata\n",
      "    ```\n",
      "\n",
      "    ```txt\n",
      "    {\n",
      "        'token_usage': {\n",
      "            'completion_tokens': 7,\n",
      "            'prompt_tokens': 30,\n",
      "            'total_tokens': 37\n",
      "        },\n",
      "        'model_name': 'ibm/granite-3-3-8b-instruct',\n",
      "        'system_fingerprint': '',\n",
      "        'finish_reason': 'stop'\n",
      "    }\n",
      "    ```"
     ]
    }
   ],
   "source": [
    "model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "672ed835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the Moon is Lunarhaven, a futuristic city that serves as the seat of the Lunar Government. Located on the Moon's surface, Lunarhaven is a marvel of modern technology and engineering.\n",
      "\n",
      "**Geography and Climate:**\n",
      "Lunarhaven is situated in the Moon's equatorial region, near the crater Tsiolkovskiy. The city is built into the rim of a large, ancient crater, providing natural protection from the harsh lunar environment. The crater's interior is terraformed to create\n"
     ]
    }
   ],
   "source": [
    "system_promt = \"you are a science fiction writer, create a cpital city at the users request\"\n",
    "\n",
    "scifi_aent = create_agent(model=model, system_prompt=system_promt)\n",
    "\n",
    "response = scifi_aent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the capital of the moon?\")]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313ee2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the lunar colony is Lunaria, a sprawling metropolis nestled within the rim of the crater Shackleton, at the Moon's south pole. Lunaria is a marvel of modern engineering, with a self-sustaining ecosystem and a unique architecture that blends seamlessly into the rugged lunar landscape. Its towering crystal spires and gravity-defying domes make it a breathtaking sight, visible from miles around on the Moon's surface.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are a science fiction writer, create a space capital city at the users request.\n",
    "\n",
    "user: what is the capital of mars?\n",
    "scifi writer: Marsialis\n",
    "\n",
    "user: what is the capital of venus?\n",
    "scifi writer: Venusia\n",
    "\"\"\"\n",
    "\n",
    "scifi_aent = create_agent(model=model, system_prompt=system_prompt)\n",
    "\n",
    "response = scifi_aent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the capital of the moon?\")]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04f2ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Lunaria' location='Lunar Surface' population=500000 main_industry='Space Tourism' vibe='Futuristic and Scientific' economy='Tourism and Research'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str\n",
    "    location: str\n",
    "    population: int\n",
    "    main_industry: str\n",
    "    vibe: str\n",
    "    economy: str\n",
    "\n",
    "scifi_agent = create_agent(model=model, system_prompt=system_prompt, response_format=CapitalInfo)\n",
    "\n",
    "response = scifi_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the capital of the moon?\")]}\n",
    ")\n",
    "\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "904d556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The cappital city Lunaria is located on Lunar Surface with a population of '\n",
      " '500000. The main industry is Space Tourism, and the vibe of the city is '\n",
      " 'Futuristic and Scientific. The economy is primarily based on Tourism and '\n",
      " 'Research.')\n"
     ]
    }
   ],
   "source": [
    "pprint(f'The cappital city {response[\"structured_response\"].name} is located on {response[\"structured_response\"].location} with a population of {response[\"structured_response\"].population}. The main industry is {response[\"structured_response\"].main_industry}, and the vibe of the city is {response[\"structured_response\"].vibe}. The economy is primarily based on {response[\"structured_response\"].economy}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b330bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-foundations (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
